# ğŸ¤– AI & GenOps Guardian

**AI & GenOps Guardian** is a multi-language **DevSecOps automation framework** that runs inside **GitHub Actions** to perform **static analysis, security scanning, and AI-assisted code review** across application code, containers, and infrastructure-as-code.

It combines **best-in-class open-source analyzers** with **LLM-based reasoning** to provide actionable insights directly in Pull Requests or as build artifacts.

---

## ğŸš€ Key Capabilities

* ğŸ” **Multi-language static analysis**
* ğŸ” **Security & IaC scanning**
* ğŸ¤– **AI-powered risk summarization**
* ğŸ’¬ **Automatic PR comments**
* ğŸ“¦ **Artifact reports for non-PR runs**
* ğŸ§  **Rate-limit safe LLM integration**
* ğŸ§± **CI-safe (never fails due to AI)**

---

## ğŸ§° Supported Languages & Tools

| Language / Area          | Tools Used                           |
| ------------------------ | ------------------------------------ |
| **Python**               | `ruff`, `pylint`, `bandit`           |
| **JavaScript / Node.js** | `eslint`                             |
| **Java**                 | `spotbugs`, `pmd`, `checkstyle`      |
| **Go**                   | `go vet`, `staticcheck`              |
| **Ruby**                 | `rubocop`                            |
| **PHP**                  | `phpcs`, `psalm`                     |
| **.NET**                 | Roslyn (`dotnet build /warnaserror`) |
| **Docker / Containers**  | `trivy`                              |
| **Terraform**            | `checkov`, `tfsec`                   |
| **Kubernetes YAML**      | `kube-linter`                        |
| **Multi-language**       | `semgrep`                            |

---

## ğŸ—ï¸ Architecture Overview

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub PR  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub Actions CI  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Language Detection       â”‚
â”‚ (ai-agent/analyzers.py)  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Static & Security Scans  â”‚
â”‚ (All tools run locally) â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Reasoning Layer       â”‚
â”‚ (OpenAI â€“ rate-safe)     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PR Comment    â”‚   â”‚ Artifacts JSON â”‚
â”‚ (PR mode)     â”‚   â”‚ (real/demo)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Execution Modes

AI & GenOps Guardian supports **three execution modes**:

| Mode   | Trigger            | Behavior                           |
| ------ | ------------------ | ---------------------------------- |
| `pr`   | Pull Request       | Posts results as PR comments       |
| `real` | Manual / scheduled | Saves JSON reports as artifacts    |
| `demo` | Manual             | Same as `real` (no PR interaction) |

Mode selection priority:

1. `workflow_dispatch` input
2. `pull_request` event â†’ `pr`
3. Default â†’ `real`

---

## ğŸ§ª Example PR Comment

```markdown
### ğŸ¤– AI & GenOps Guardian Report

Mode: pr

Summary:
Potential security misconfigurations detected in Terraform
and inconsistent linting in Python modules.

Critical Issues:
- Terraform S3 bucket allows public access
- Hardcoded secret detected by Semgrep

Recommendations:
- Enable S3 Block Public Access
- Move secrets to GitHub Secrets or Vault
```

---

## ğŸ› ï¸ Repository Structure

```text
.
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ai-genops.yml
â”‚
â”œâ”€â”€ ai-agent/
â”‚   â”œâ”€â”€ agent.py        # Orchestrator (PR vs real mode)
â”‚   â”œâ”€â”€ analyzers.py    # Tool execution & language detection
â”‚   â”œâ”€â”€ llm.py          # LLM integration (rate-limit safe)
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ analysis_results/   # Generated in real/demo mode
```

---

## ğŸ” Required Secrets

Add the following secrets in your repository settings:

| Secret Name      | Description                     |
| ---------------- | ------------------------------- |
| `OPENAI_API_KEY` | OpenAI API key                  |
| `GITHUB_TOKEN`   | Auto-provided by GitHub Actions |

> âš ï¸ **Do not** hardcode tokens or secrets in code.

---

## ğŸ§  LLM Safety & Reliability

The AI layer is **CI-safe by design**:

* ğŸ§® Prompt size capped to avoid token explosion
* ğŸ” Automatic retry with exponential backoff
* âœ‚ï¸ Analyzer output summarization
* ğŸ§± Hard fallback when rate-limited
* âŒ Pipeline **never fails due to AI**

If OpenAI is unavailable, **static analysis still completes**.

---

## ğŸ“¦ Outputs

### PR Mode

* Comments posted directly on the Pull Request

### Real / Demo Mode

* `analysis_results/report.json`
* Uploaded as GitHub Action artifacts

---

## ğŸ§© Extensibility

Designed for easy extension:

* Add SARIF output
* Add policy gates (fail on Critical)
* Add diff-aware analysis (BASE vs HEAD)
* Plug in Bedrock / Azure OpenAI
* Split LLM analysis per language

---

## ğŸ† Use Cases

* Secure CI/CD pipelines
* Enterprise DevSecOps automation
* Code quality enforcement
* IaC security governance
* AI-assisted code reviews

---

## ğŸ‘¤ Author

**Sourav Chandra**
DevSecOps â€¢ GenAI â€¢ Platform Engineering

---
